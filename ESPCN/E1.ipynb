{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Dakewe Biotech Corporation. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "__all__ = [\n",
    "    \"ESPCN\",\n",
    "    \"espcn_x2\", \"espcn_x3\", \"espcn_x4\", \"espcn_x8\",\n",
    "]\n",
    "\n",
    "\n",
    "class ESPCN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            channels: int,\n",
    "            upscale_factor: int,\n",
    "    ) -> None:\n",
    "        super(ESPCN, self).__init__()\n",
    "        hidden_channels = channels // 2\n",
    "        out_channels = int(out_channels * (upscale_factor ** 2))\n",
    "\n",
    "        # Feature mapping\n",
    "        self.feature_maps = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, channels, (5, 5), (1, 1), (2, 2)),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(channels, hidden_channels, (3, 3), (1, 1), (1, 1)),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        # Sub-pixel convolution layer\n",
    "        self.sub_pixel = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, (3, 3), (1, 1), (1, 1)),\n",
    "            nn.PixelShuffle(upscale_factor),\n",
    "        )\n",
    "\n",
    "        # Initial model weights\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                if module.in_channels == 32:\n",
    "                    nn.init.normal_(module.weight.data,\n",
    "                                    0.0,\n",
    "                                    0.001)\n",
    "                    nn.init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    nn.init.normal_(module.weight.data,\n",
    "                                    0.0,\n",
    "                                    math.sqrt(2 / (module.out_channels * module.weight.data[0][0].numel())))\n",
    "                    nn.init.zeros_(module.bias.data)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    # Support torch.script function.\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.feature_maps(x)\n",
    "        x = self.sub_pixel(x)\n",
    "\n",
    "        x = torch.clamp_(x, 0.0, 1.0)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def espcn_x2(**kwargs) -> ESPCN:\n",
    "    model = ESPCN(upscale_factor=2, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def espcn_x3(**kwargs) -> ESPCN:\n",
    "    model = ESPCN(upscale_factor=3, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def espcn_x4(**kwargs) -> ESPCN:\n",
    "    model = ESPCN(upscale_factor=4, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def espcn_x8(**kwargs) -> ESPCN:\n",
    "    model = ESPCN(upscale_factor=8, **kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,image_dir, upscale_factor, mode = 'train'):\n",
    "        self.image_dir - image_dir\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.mode = mode \n",
    "        self.image_filemname = [os.path.join(image_dir,x) for x in os.listdir(image_dir)]\n",
    "        self.transform = transforms.Compose([transforms.ToTesnor(),transform.Normalize(mean = [0.5,0.5,0.5], std = [0.5,0.5,0.5])])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filename)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image = Image.open(self.image_filenames[idx]).convert('RGB')        \n",
    "        if self.mode == 'train':\n",
    "            lr_image = image.resize((image.size[0]//self.upscale_factor,image.size[1]//self.upscale_factor),Image.BICUBIC)\n",
    "            hr_image = image\n",
    "        else:\n",
    "            lr_image = image\n",
    "            hr_image = None\n",
    "\n",
    "        lr_image = self.transform(lr_image)        \n",
    "        if hr_image is not Nonne:\n",
    "            hr_image = self.transform(hr_image)\n",
    "        else:\n",
    "            return lr_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_oader,criterion,optimizer,device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for lr_image,hr_images in train_loader:\n",
    "        lr_images = lr_images.to(device)\n",
    "        hr_images = hr_images.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(lr_images)\n",
    "        loss = criterion(outputs,hr_images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, test_loader,device):\n",
    "    model.eval()\n",
    "    torch_psnr = 0.0\n",
    "    with torch.no_grad():\n",
    "        for lr_images in test_loader:\n",
    "            lr_images = lr_images.to(device)        \n",
    "            outputs = model(lr_images)\n",
    "            outputs = outputs.clamp(0.0,1.0)\n",
    "            total_psnr += calculate_psnr(outputs,lr_images)\n",
    "\n",
    "    return total_psnr/len(test_holder)        \n",
    "\n",
    "\n",
    "def calculate_psnr(img1,img2):\n",
    "    mse = torch.mean((img1 - img)**2)\n",
    "    if mse == 0:\n",
    "        return float('inf')    \n",
    "    return 20*torch.log10(1.0/torch.sqrt(mse))    \n",
    "\n",
    "\n",
    "def save_model(model,path):\n",
    "    torch.save(model.state_dict(),path)\n",
    "\n",
    "def load_model(model,path,device):\n",
    "    model.load_state_dict(torch.load(path,map_location=device)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    upscale_factor = 2\n",
    "    in_channels = 3\n",
    "    out_channels = 3\n",
    "    channels = 64\n",
    "    batch_size = 16\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    train_image_dir = r'C:\\Users\\91995\\Downloads\\div2k\\DIV2K_train_HR\\DIV2K_train_HR'\n",
    "    test_image_dir = r'C:\\Users\\91995\\OneDrive\\Desktop\\ESCPN++\\Set14\\Set14_4'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = ESPCN(in_channels,out_channels,channels,upscale_factor).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "    train_dataset = ImageDataset(train_image_dir,upscale_factor,mode = 'train')\n",
    "    test_dataset = ImageDataset(test_image_dir,upscale_factor,mode = 'test')\n",
    "    train_loader = DataLoader(train_dataset,batch_size = 1,shuffle = True)\n",
    "    test_loader = DataLoader(test_dataset,batch_size = 1,shuffle = False)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, tran_loader,criterion,optimizer,device)\n",
    "\n",
    "        if(epoch+1)%10 == 0:\n",
    "            avg_psnr = test(model,test_loader,device)\n",
    "            print(f'PSNR : {avg_psnr:.2f}dB')\n",
    "            save_model(model,f'espcn_x{upscale_factor}_epoch_{epoch + 1}.pth')    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == 'main':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
