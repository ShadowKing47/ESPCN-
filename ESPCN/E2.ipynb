{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "\n",
    "# Custom dataset for super-resolution training\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, image_dir, scale_factor, patch_size=96, is_training=True):\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, \"*.png\")) + \\\n",
    "                          glob.glob(os.path.join(image_dir, \"*.jpg\")) + \\\n",
    "                          glob.glob(os.path.join(image_dir, \"*.jpeg\"))\n",
    "        self.scale_factor = scale_factor\n",
    "        self.patch_size = patch_size\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        # For testing, we use the full images\n",
    "        if not is_training:\n",
    "            self.lr_transforms = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            self.hr_transforms = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        # For training, we extract random patches\n",
    "        else:\n",
    "            self.lr_transforms = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            self.hr_transforms = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        hr_img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.is_training:\n",
    "            # Get random patch for training\n",
    "            hr_width, hr_height = hr_img.size\n",
    "            lr_patch_size = self.patch_size // self.scale_factor\n",
    "            \n",
    "            # Ensure the image is large enough for patch extraction\n",
    "            if hr_width < self.patch_size or hr_height < self.patch_size:\n",
    "                hr_img = transforms.Resize((max(self.patch_size, hr_height), \n",
    "                                           max(self.patch_size, hr_width)))(hr_img)\n",
    "                hr_width, hr_height = hr_img.size\n",
    "            \n",
    "            # Random crop\n",
    "            left = np.random.randint(0, hr_width - self.patch_size)\n",
    "            top = np.random.randint(0, hr_height - self.patch_size)\n",
    "            right = left + self.patch_size\n",
    "            bottom = top + self.patch_size\n",
    "            \n",
    "            hr_img = hr_img.crop((left, top, right, bottom))\n",
    "            \n",
    "            # Create LR image through downsampling\n",
    "            lr_img = hr_img.resize((lr_patch_size, lr_patch_size), Image.BICUBIC)\n",
    "            \n",
    "            # Apply data augmentation (random flips and rotations)\n",
    "            if np.random.random() > 0.5:\n",
    "                hr_img = hr_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                lr_img = lr_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            if np.random.random() > 0.5:\n",
    "                hr_img = hr_img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                lr_img = lr_img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            \n",
    "            rotation = np.random.choice([0, 90, 180, 270])\n",
    "            if rotation > 0:\n",
    "                hr_img = hr_img.rotate(rotation)\n",
    "                lr_img = lr_img.rotate(rotation)\n",
    "                \n",
    "        else:\n",
    "            # For testing, resize the entire image\n",
    "            hr_width, hr_height = hr_img.size\n",
    "            lr_img = hr_img.resize((hr_width // self.scale_factor, hr_height // self.scale_factor), Image.BICUBIC)\n",
    "            \n",
    "        # Convert to tensor\n",
    "        lr_tensor = self.lr_transforms(lr_img)\n",
    "        hr_tensor = self.hr_transforms(hr_img)\n",
    "        \n",
    "        return {\"lr\": lr_tensor, \"hr\": hr_tensor}\n",
    "\n",
    "def train_espcn(model, train_dir, val_dir, scale_factor, batch_size=16, patch_size=96, num_epochs=100, \n",
    "               learning_rate=1e-3, device='cuda', save_path='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Train the ESPCN model\n",
    "    \n",
    "    Args:\n",
    "        model: ESPCN model instance\n",
    "        train_dir: Directory containing training images\n",
    "        val_dir: Directory containing validation images\n",
    "        scale_factor: Super-resolution scale factor\n",
    "        batch_size: Training batch size\n",
    "        patch_size: Size of HR image patches for training\n",
    "        num_epochs: Number of training epochs\n",
    "        learning_rate: Learning rate\n",
    "        device: Device for training ('cuda' or 'cpu')\n",
    "        save_path: Path to save the best model weights\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(device if torch.cuda.is_available() and device == 'cuda' else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = SRDataset(train_dir, scale_factor=scale_factor, patch_size=patch_size, is_training=True)\n",
    "    val_dataset = SRDataset(val_dir, scale_factor=scale_factor, is_training=False)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # Training loop\n",
    "    best_psnr = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_psnr = 0.0\n",
    "        \n",
    "        with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "            for batch in train_dataloader:\n",
    "                lr_imgs = batch[\"lr\"].to(device)\n",
    "                hr_imgs = batch[\"hr\"].to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                sr_imgs = model(lr_imgs)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = criterion(sr_imgs, hr_imgs)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Calculate PSNR\n",
    "                batch_psnr = 10 * torch.log10(1.0 / loss).item()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_psnr += batch_psnr\n",
    "                \n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"loss\": loss.item(), \"PSNR\": batch_psnr})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        avg_train_psnr = train_psnr / len(train_dataloader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_psnr = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                lr_imgs = batch[\"lr\"].to(device)\n",
    "                hr_imgs = batch[\"hr\"].to(device)\n",
    "                \n",
    "                sr_imgs = model(lr_imgs)\n",
    "                loss = criterion(sr_imgs, hr_imgs)\n",
    "                \n",
    "                batch_psnr = 10 * torch.log10(1.0 / loss).item()\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_psnr += batch_psnr\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        avg_val_psnr = val_psnr / len(val_dataloader)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Save the best model\n",
    "        if avg_val_psnr > best_psnr:\n",
    "            best_psnr = avg_val_psnr\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Best model saved with PSNR: {best_psnr:.2f} dB\")\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.6f}, Train PSNR: {avg_train_psnr:.2f} dB\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.6f}, Val PSNR: {avg_val_psnr:.2f} dB\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 10 * torch.log10(1.0 / mse)\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    \"\"\"Calculate SSIM between two images\"\"\"\n",
    "    C1 = (0.01 * 1) ** 2\n",
    "    C2 = (0.03 * 1) ** 2\n",
    "    \n",
    "    img1 = img1.unsqueeze(0)\n",
    "    img2 = img2.unsqueeze(0)\n",
    "\n",
    "    mu1 = torch.nn.functional.avg_pool2d(img1, kernel_size=11, stride=1, padding=5)\n",
    "    mu2 = torch.nn.functional.avg_pool2d(img2, kernel_size=11, stride=1, padding=5)\n",
    "    \n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    \n",
    "    sigma1_sq = torch.nn.functional.avg_pool2d(img1 * img1, kernel_size=11, stride=1, padding=5) - mu1_sq\n",
    "    sigma2_sq = torch.nn.functional.avg_pool2d(img2 * img2, kernel_size=11, stride=1, padding=5) - mu2_sq\n",
    "    sigma12 = torch.nn.functional.avg_pool2d(img1 * img2, kernel_size=11, stride=1, padding=5) - mu1_mu2\n",
    "    \n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean().item()\n",
    "\n",
    "def test_espcn(model, test_dir, output_dir, scale_factor, device='cuda'):\n",
    "    \"\"\"\n",
    "    Test the ESPCN model on a directory of test images\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ESPCN model instance\n",
    "        test_dir: Directory containing test images\n",
    "        output_dir: Directory to save super-resolution results\n",
    "        scale_factor: Super-resolution scale factor\n",
    "        device: Device for inference ('cuda' or 'cpu')\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(device if torch.cuda.is_available() and device == 'cuda' else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all image paths\n",
    "    image_paths = glob.glob(os.path.join(test_dir, \"*.png\")) + \\\n",
    "                  glob.glob(os.path.join(test_dir, \"*.jpg\")) + \\\n",
    "                  glob.glob(os.path.join(test_dir, \"*.jpeg\"))\n",
    "    \n",
    "    # Metrics\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in tqdm(image_paths, desc=\"Testing\"):\n",
    "        # Load image\n",
    "        img_name = os.path.basename(img_path)\n",
    "        hr_img = Image.open(img_path).convert('RGB')\n",
    "        hr_width, hr_height = hr_img.size\n",
    "        \n",
    "        # Create bicubic upscaled image for comparison\n",
    "        lr_img = hr_img.resize((hr_width // scale_factor, hr_height // scale_factor), Image.BICUBIC)\n",
    "        bicubic_img = lr_img.resize((hr_width, hr_height), Image.BICUBIC)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        lr_tensor = to_tensor(lr_img).unsqueeze(0).to(device)\n",
    "        hr_tensor = to_tensor(hr_img).to(device)\n",
    "        bicubic_tensor = to_tensor(bicubic_img).to(device)\n",
    "        \n",
    "        # Generate SR image\n",
    "        with torch.no_grad():\n",
    "            sr_tensor = model(lr_tensor).squeeze(0).clamp(0.0, 1.0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        psnr_val = calculate_psnr(sr_tensor, hr_tensor)\n",
    "        ssim_val = calculate_ssim(sr_tensor, hr_tensor)\n",
    "        bicubic_psnr = calculate_psnr(bicubic_tensor, hr_tensor)\n",
    "        bicubic_ssim = calculate_ssim(bicubic_tensor, hr_tensor)\n",
    "        \n",
    "        total_psnr += psnr_val\n",
    "        total_ssim += ssim_val\n",
    "        \n",
    "        # Save SR image\n",
    "        sr_img = to_pil_image(sr_tensor.cpu())\n",
    "        sr_img.save(os.path.join(output_dir, f\"SR_{img_name}\"))\n",
    "        \n",
    "        # Save bicubic image for comparison\n",
    "        bicubic_img.save(os.path.join(output_dir, f\"Bicubic_{img_name}\"))\n",
    "        \n",
    "        # Save LR image\n",
    "        lr_img.save(os.path.join(output_dir, f\"LR_{img_name}\"))\n",
    "        \n",
    "        # Print metrics for this image\n",
    "        print(f\"Image: {img_name}\")\n",
    "        print(f\"ESPCN - PSNR: {psnr_val:.2f} dB, SSIM: {ssim_val:.4f}\")\n",
    "        print(f\"Bicubic - PSNR: {bicubic_psnr:.2f} dB, SSIM: {bicubic_ssim:.4f}\")\n",
    "        print(f\"Improvement - PSNR: {psnr_val - bicubic_psnr:.2f} dB, SSIM: {ssim_val - bicubic_ssim:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Print average metrics\n",
    "    avg_psnr = total_psnr / len(image_paths)\n",
    "    avg_ssim = total_ssim / len(image_paths)\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model\n",
    "    model = ESPCN(\n",
    "        in_channels=3,  # RGB image\n",
    "        out_channels=3,  # RGB output\n",
    "        channels=64,    # Number of feature channels\n",
    "        upscale_factor=4 # Upscaling factor\n",
    "    )\n",
    "    \n",
    "    # Example directories\n",
    "    train_dir = \"dataset/train\"\n",
    "    val_dir = \"dataset/val\"\n",
    "    test_dir = \"dataset/test\"\n",
    "    output_dir = \"results\"\n",
    "    \n",
    "    # Train the model\n",
    "    train_espcn(\n",
    "        model=model,\n",
    "        train_dir=train_dir,\n",
    "        val_dir=val_dir,\n",
    "        scale_factor=4,\n",
    "        batch_size=16,\n",
    "        patch_size=96,\n",
    "        num_epochs=100,\n",
    "        device='cuda',\n",
    "        save_path='best_espcn_x4.pth'\n",
    "    )\n",
    "    \n",
    "    # Load best model for testing\n",
    "    model.load_state_dict(torch.load('best_espcn_x4.pth'))\n",
    "    \n",
    "    # Test the model\n",
    "    test_espcn(\n",
    "        model=model,\n",
    "        test_dir=test_dir,\n",
    "        output_dir=output_dir,\n",
    "        scale_factor=4,\n",
    "        device='cuda'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
